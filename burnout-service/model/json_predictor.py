import pandas as pd
import numpy as np
import json
import joblib
from sklearn.preprocessing import LabelEncoder
from datetime import datetime

class JSONPredictor:
    def __init__(self, model_path='svm_model.pkl'):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—è –¥–ª—è JSON –¥–∞–Ω–Ω—ã—Ö"""
        try:
            model_data = joblib.load(model_path)
            self.model = model_data['model']
            self.scaler = model_data['scaler']
            self.metrics = model_data.get('metrics', {})
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {model_path}")
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –º–æ–¥–µ–ª–∏ –∏–ª–∏ scaler
            self.expected_features = self._get_real_expected_features()
            print(f"üìä –†–µ–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –º–æ–¥–µ–ª–∏: {len(self.expected_features)}")
            
        except FileNotFoundError:
            print(f"‚ùå –ú–æ–¥–µ–ª—å {model_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            self.model = None
            self.scaler = None
            self.expected_features = None

    def _get_real_expected_features(self):
        """–ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –º–æ–¥–µ–ª–∏ –∏–ª–∏ scaler"""
        if hasattr(self.scaler, 'feature_names_in_'):
            return list(self.scaler.feature_names_in_)
        elif hasattr(self.model, 'feature_names_in_'):
            return list(self.model.feature_names_in_)
        else:
            print("‚ö†Ô∏è  –ü—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –º–æ–¥–µ–ª–∏, —Å–æ–∑–¥–∞–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ CSV —Å—Ç—Ä—É–∫—Ç—É—Ä—ã")
            return self._get_fallback_features()

    def _get_fallback_features(self):
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ CSV —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        expected_features = [
            '–≤–æ–∑—Ä–∞—Å—Ç', 'KPI_–∏—é–Ω—å', 'KPI_–∏—é–ª—å', 'KPI_–∞–≤–≥—É—Å—Ç', 'KPI_—Å–µ–Ω—Ç—è–±—Ä—å', 'KPI_–æ–∫—Ç—è–±—Ä—å',
            '–û–±—É—á–µ–Ω–∏–µ', '–°—Ç–∞–∂_–º–µ—Å—è—Ü—ã', 'KPI_–∑–∞–ø–æ–ª–Ω–µ–Ω–æ_–ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π', 'KPI_—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å',
            'KPI_–º–∏–Ω', 'KPI_–º–∞–∫—Å', 'KPI_—Ä–∞–∑–º–∞—Ö', 'KPI_—Ç—Ä–µ–Ω–¥', 'KPI_–ø–æ—Å–ª–µ–¥–Ω–∏–π',
            '–û—Ç–ø—É—Å–∫_–º–µ—Å—è—Ü–µ–≤_–Ω–∞–∑–∞–¥', '–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å'
        ]
        
        positions = [
            '–ë—Ä–∏–≥–∞–¥–∏—Ä', '–ë—É—Ö–≥–∞–ª—Ç–µ—Ä', '–ì–ª–∞–≤–Ω—ã–π –±—É—Ö–≥–∞–ª—Ç–µ—Ä', '–î–∏–∑–∞–π–Ω–µ—Ä', '–î–∏—Ä–µ–∫—Ç–æ—Ä —Ñ–∏–ª–∏–∞–ª–∞',
            '–ö–∞—Å—Å–∏—Ä', '–ö–ª–∞–¥–æ–≤—â–∏–∫', '–ö—É—Ä—å–µ—Ä', '–õ–æ–≥–∏—Å—Ç', '–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º',
            '–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Ä–∞–±–æ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏', '–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω–æ–º—É —Ä–∞–∑–≤–∏—Ç–∏.',
            '–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –±—ç–∫–µ–Ω–¥', '–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ —Ñ—Ä–æ–Ω—Ç', '–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∫–ª–∏–µ–Ω—Ç—Å–æ–∫–≥–æ –æ—Ç–¥–µ–ª–∞',
            '–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∫–æ–Ω—Ç–∞–∫—Ç–Ω–æ–≥–æ-—Ü–µ–Ω—Ç—Ä–∞ 1 –ª–∏–Ω–∏–∏', '–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –æ—Ç–¥–µ–ª–∞ –ø—Ä–æ–¥–∞–∂',
            '–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞', '–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Å–∫–ª–∞–¥–∞',
            '–°—Ç–∞—Ä—à–∏–π –º–µ–Ω–µ–¥–∂–µ—Ä –≥—Ä—É–ø–ø—ã —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è –ø–æ –∫–ª–∏–µ–Ω—Ç—Å–∫–æ–º—É —Å–µ—Ä–≤–∏—Å—É',
            '–°—Ç–∞—Ä—à–∏–π –º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Ä–∞–±–æ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏', '–¢–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫', '–Æ—Ä–∏—Å—Ç'
        ]
        
        for pos in positions:
            expected_features.append(f'–î–æ–ª–∂–Ω–æ—Å—Ç—å_{pos}')
        
        return expected_features

    def load_json_data(self, json_path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"‚úÖ JSON –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ {json_path}")
            return data
        except FileNotFoundError:
            print(f"‚ùå JSON —Ñ–∞–π–ª {json_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
        except json.JSONDecodeError:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON —Ñ–∞–π–ª–∞ {json_path}")
            return None

    def transform_to_model_features(self, employee_data):
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç –º–æ–¥–µ–ª–∏"""
        data = employee_data.copy()
        all_possible_features = {}
        
        # 1. –ë–∞–∑–æ–≤—ã–µ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ - –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–æ–∑—Ä–∞—Å—Ç
        age = data.get('–≤–æ–∑—Ä–∞—Å—Ç', 30.0)
        all_possible_features['–≤–æ–∑—Ä–∞—Å—Ç'] = float(age) / 100.0  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–æ–∑—Ä–∞—Å—Ç
        
        # 2. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–∂–∞ –≤ –º–µ—Å—è—Ü—ã - –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        experience_months = self._experience_to_months(data.get('–°—Ç–∞–∂', '2 –≥–æ–¥–∞'))
        all_possible_features['–°—Ç–∞–∂_–º–µ—Å—è—Ü—ã'] = float(experience_months) / 120.0  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 10 –≥–æ–¥–∞–º
        
        # 3. KPI –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç 0 –¥–æ 1
        kpi_months = ['–∏—é–Ω—å', '–∏—é–ª—å', '–∞–≤–≥—É—Å—Ç', '—Å–µ–Ω—Ç—è–±—Ä—å', '–æ–∫—Ç—è–±—Ä—å']
        kpi_values = []
        
        for month in kpi_months:
            kpi_value = data.get(month, 0.8)
            if isinstance(kpi_value, str):
                try:
                    kpi_value = float(kpi_value) 
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è KPI –æ—Ç 0 –¥–æ 1
                    kpi_value = max(0.0, min(1.0, kpi_value))
                except:
                    kpi_value = 0.8
            all_possible_features[f'KPI_{month}'] = float(kpi_value)
            kpi_values.append(float(kpi_value))
        
        # 4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ KPI - –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏
        kpi_array = np.array(kpi_values)
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö KPI (–æ—Ç 0 –¥–æ 5)
        all_possible_features['KPI_–∑–∞–ø–æ–ª–Ω–µ–Ω–æ_–ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π'] = float(len([x for x in kpi_values if x > 0])) / 5.0
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ KPI (–Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 0.5)
        std_value = kpi_array.std() if len(kpi_values) > 1 else 0.1
        all_possible_features['KPI_—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å'] = float(std_value) / 0.5
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ KPI (—É–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã –æ—Ç 0 –¥–æ 1)
        all_possible_features['KPI_–º–∏–Ω'] = float(kpi_array.min())
        all_possible_features['KPI_–º–∞–∫—Å'] = float(kpi_array.max())
        
        # –†–∞–∑–º–∞—Ö KPI (–Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 1.0)
        kpi_range = kpi_array.max() - kpi_array.min()
        all_possible_features['KPI_—Ä–∞–∑–º–∞—Ö'] = float(kpi_range)
        
        # –¢—Ä–µ–Ω–¥ KPI (–Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 0.1)
        if len(kpi_values) >= 2:
            x = np.arange(len(kpi_values))
            try:
                trend = np.polyfit(x, kpi_values, 1)[0]
                all_possible_features['KPI_—Ç—Ä–µ–Ω–¥'] = float(trend) / 0.1
            except:
                all_possible_features['KPI_—Ç—Ä–µ–Ω–¥'] = 0.0
        else:
            all_possible_features['KPI_—Ç—Ä–µ–Ω–¥'] = 0.0
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–π KPI (—É–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω)
        all_possible_features['KPI_–ø–æ—Å–ª–µ–¥–Ω–∏–π'] = float(kpi_values[-1] if kpi_values else 0.8)
        
        # 5. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–ø—É—Å–∫–∞ - –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 24 –º–µ—Å—è—Ü–∞–º
        vacation_date = data.get('–û—Ç–ø—É—Å–∫ (–∫–æ–≥–¥–∞ —Ö–æ–¥–∏–ª –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑)', '–Ω–µ—Ç')
        vacation_months = self._vacation_months_ago(vacation_date)
        all_possible_features['–û—Ç–ø—É—Å–∫_–º–µ—Å—è—Ü–µ–≤_–Ω–∞–∑–∞–¥'] = float(vacation_months) / 24.0
        
        # 6. –û–±—É—á–µ–Ω–∏–µ - –±–∏–Ω–∞—Ä–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫
        training_key = data.get('–û–±—É—á–µ–Ω–∏–µ', '–≤ –ø—Ä–æ—Ü–µ—Å—Å–µ')
        binary_mapping = {
            '–¥–∞': 1, '–Ω–µ—Ç': 0, 'yes': 1, 'no': 0,
            '–ø—Ä–æ—à–µ–ª': 1, '–Ω–µ –ø—Ä–æ—à–µ–ª': 0, '–Ω–µ—Ç –∞—Ç—Ç–µ—Å—Ç–∞—Ü–∏–∏': 0,
            '–∑–∞–≤–µ—Ä—à–µ–Ω–∞': 1, '–≤ –ø—Ä–æ—Ü–µ—Å—Å–µ': 0, '–∑–∞–≤–µ—Ä—à–µ–Ω–æ': 1
        }
        all_possible_features['–û–±—É—á–µ–Ω–∏–µ'] = float(binary_mapping.get(training_key, 0))
        
        # 7. –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å - –±–∏–Ω–∞—Ä–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫
        manager_key = data.get('–í –ø–æ–¥—á–∏–Ω–µ–Ω–Ω–∏–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏', '–°–æ—Ç—Ä—É–¥–Ω–∏–∫')
        manager_mapping = {
            '–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å': 1, '–°–æ—Ç—Ä—É–¥–Ω–∏–∫': 0, '–¥–∞': 1, '–Ω–µ—Ç': 0
        }
        all_possible_features['–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å'] = float(manager_mapping.get(manager_key, 0))
        
        # 8. –î–æ–ª–∂–Ω–æ—Å—Ç–∏ - one-hot encoding
        positions = [
            '–ë—Ä–∏–≥–∞–¥–∏—Ä', '–ë—É—Ö–≥–∞–ª—Ç–µ—Ä', '–ì–ª–∞–≤–Ω—ã–π –±—É—Ö–≥–∞–ª—Ç–µ—Ä', '–î–∏–∑–∞–π–Ω–µ—Ä', '–î–∏—Ä–µ–∫—Ç–æ—Ä —Ñ–∏–ª–∏–∞–ª–∞',
            '–ö–∞—Å—Å–∏—Ä', '–ö–ª–∞–¥–æ–≤—â–∏–∫', '–ö—É—Ä—å–µ—Ä', '–õ–æ–≥–∏—Å—Ç', '–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º',
            '–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Ä–∞–±–æ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏', '–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω–æ–º—É —Ä–∞–∑–≤–∏—Ç–∏.',
            '–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –±—ç–∫–µ–Ω–¥', '–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ —Ñ—Ä–æ–Ω—Ç', '–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∫–ª–∏–µ–Ω—Ç—Å–æ–∫–≥–æ –æ—Ç–¥–µ–ª–∞',
            '–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∫–æ–Ω—Ç–∞–∫—Ç–Ω–æ–≥–æ-—Ü–µ–Ω—Ç—Ä–∞ 1 –ª–∏–Ω–∏–∏', '–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –æ—Ç–¥–µ–ª–∞ –ø—Ä–æ–¥–∞–∂',
            '–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞', '–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Å–∫–ª–∞–¥–∞',
            '–°—Ç–∞—Ä—à–∏–π –º–µ–Ω–µ–¥–∂–µ—Ä –≥—Ä—É–ø–ø—ã —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è –ø–æ –∫–ª–∏–µ–Ω—Ç—Å–∫–æ–º—É —Å–µ—Ä–≤–∏—Å—É',
            '–°—Ç–∞—Ä—à–∏–π –º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Ä–∞–±–æ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏', '–¢–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫', '–Æ—Ä–∏—Å—Ç'
        ]
        
        for pos_name in positions:
            all_possible_features[f'–î–æ–ª–∂–Ω–æ—Å—Ç—å_{pos_name}'] = 0.0
        
        current_position = data.get('–î–æ–ª–∂–Ω–æ—Å—Ç—å', '–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Ä–∞–±–æ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏')
        for pos_name in positions:
            if current_position == pos_name:
                all_possible_features[f'–î–æ–ª–∂–Ω–æ—Å—Ç—å_{pos_name}'] = 1.0
                break
        else:
            if '–º–µ–Ω–µ–¥–∂–µ—Ä' in current_position.lower() or '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å' in current_position.lower():
                all_possible_features['–î–æ–ª–∂–Ω–æ—Å—Ç—å_–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Ä–∞–±–æ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏'] = 1.0
            else:
                all_possible_features['–î–æ–ª–∂–Ω–æ—Å—Ç—å_–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Ä–∞–±–æ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏'] = 1.0
        
        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø–æ—Ä—è–¥–∫–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        df_all = pd.DataFrame([all_possible_features])
        processed_data = {}
        
        if self.expected_features:
            for feature in self.expected_features:
                if feature in df_all.columns:
                    processed_data[feature] = df_all[feature].iloc[0]
                else:
                    processed_data[feature] = 0.0
        else:
            processed_data = all_possible_features
        
        df = pd.DataFrame([processed_data])
        
        if self.expected_features:
            df = df[self.expected_features]
        
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        print(f"üîç –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df.columns)}")
        print(f"üìä –î–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π: [{df.min().min():.3f}, {df.max().max():.3f}]")
        print(f"üìà –ü—Ä–∏–º–µ—Ä KPI: {[df[f'KPI_{month}'].iloc[0] for month in ['–∏—é–Ω—å', '–∏—é–ª—å', '–∞–≤–≥—É—Å—Ç']]}")
        
        return df

    def _experience_to_months(self, experience_str):
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–∂–∞ –≤ –º–µ—Å—è—Ü—ã"""
        if isinstance(experience_str, (int, float)):
            return min(int(experience_str), 120)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 10 –≥–æ–¥–∞–º–∏
        
        if not isinstance(experience_str, str):
            return 24
        
        total_months = 0
        try:
            if '–≥–æ–¥' in experience_str:
                years_match = experience_str.split('–≥–æ–¥')[0].strip()
                if years_match.isdigit():
                    total_months += min(int(years_match) * 12, 120)
            elif '–ª–µ—Ç' in experience_str:
                years_match = experience_str.split('–ª–µ—Ç')[0].strip()
                if years_match.isdigit():
                    total_months += min(int(years_match) * 12, 120)
            
            if '–º–µ—Å—è—Ü' in experience_str:
                months_part = experience_str.split('–º–µ—Å—è—Ü')[0]
                months_match = months_part.split()[-1]
                if months_match.isdigit():
                    total_months += min(int(months_match), 11)
        except:
            pass
        
        return total_months if total_months > 0 else 24

    def _vacation_months_ago(self, vacation_date):
        """–†–∞—Å—á–µ—Ç —Å–∫–æ–ª—å–∫–æ –º–µ—Å—è—Ü–µ–≤ –Ω–∞–∑–∞–¥ –±—ã–ª –æ—Ç–ø—É—Å–∫"""
        if not vacation_date or vacation_date == '–Ω–µ—Ç':
            return 12
        
        try:
            if isinstance(vacation_date, str):
                for fmt in ['%Y-%m-%d', '%d.%m.%Y', '%Y-%m-%d %H:%M:%S']:
                    try:
                        vacation_dt = datetime.strptime(vacation_date, fmt)
                        break
                    except:
                        continue
                else:
                    return 12
            
            current_date = datetime(2025, 1, 1)
            months_ago = (current_date.year - vacation_dt.year) * 12 + (current_date.month - vacation_dt.month)
            return min(max(1, months_ago), 24)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 2 –≥–æ–¥–∞–º–∏
        except:
            return 12

    def process_single_employee(self, employee_data):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–¥–Ω–æ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞"""
        processed_data = self.transform_to_model_features(employee_data)
        print(f"üî¢ –§–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö: {processed_data.shape}")
        return processed_data

    def predict_burnout(self, processed_data):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤—ã–≥–æ—Ä–∞–Ω–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if self.model is None:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return None
        
        print(f"üéØ –î–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {processed_data.shape}")
        
        try:
            scaled_data = self.scaler.transform(processed_data)
            print(f"üìê –î–∏–∞–ø–∞–∑–æ–Ω –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: [{scaled_data.min():.3f}, {scaled_data.max():.3f}]")
        except ValueError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None
        
        prediction = self.model.predict(scaled_data)
        probability = self.model.predict_proba(scaled_data)
        
        print(f"üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {prediction[0]}")
        print(f"üìä –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: [–ù–æ—Ä–º–∞: {probability[0, 0]:.3f}, –í—ã–≥–æ—Ä–∞–Ω–∏–µ: {probability[0, 1]:.3f}]")
        
        return {
            'prediction': int(prediction[0]),
            'burnout_probability': float(probability[0, 1]),
            'no_burnout_probability': float(probability[0, 0]),
            'confidence': float(max(probability[0]))
        }

    def interpret_prediction(self, prediction_result):
        """–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
        prediction = prediction_result['prediction']
        burnout_prob = prediction_result['burnout_probability']
        
        if prediction == 1:
            status = "–í–´–ì–û–†–ê–ù–ò–ï"
            if burnout_prob > 0.7:
                recommendation = "‚ùó –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –≤—ã–≥–æ—Ä–∞–Ω–∏—è. –¢—Ä–µ–±—É–µ—Ç—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ"
            elif burnout_prob > 0.5:
                recommendation = "‚ö†Ô∏è  –°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫ –≤—ã–≥–æ—Ä–∞–Ω–∏—è. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∞"
            else:
                recommendation = "‚ö†Ô∏è  –í–æ–∑–º–æ–∂–Ω–æ–µ –≤—ã–≥–æ—Ä–∞–Ω–∏–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ"
            color = "üî¥"
        else:
            status = "–ù–û–†–ú–ê"
            if burnout_prob < 0.2:
                recommendation = "‚úÖ –û—Ç–ª–∏—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ. –ü—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Ç–µ–∫—É—â–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏"
            elif burnout_prob < 0.4:
                recommendation = "‚úÖ –•–æ—Ä–æ—à–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∞"
            else:
                recommendation = "üü° –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ"
            color = "üü¢"
        
        return {
            'status': status,
            'probability': burnout_prob,
            'recommendation': recommendation,
            'color': color
        }

    def process_json_file(self, json_path):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ–≥–æ JSON —Ñ–∞–π–ª–∞"""
        data = self.load_json_data(json_path)
        if data is None:
            return None
        
        results = []
        
        if isinstance(data, list):
            employees = data
        elif isinstance(data, dict):
            if 'employees' in data:
                employees = data['employees']
            else:
                employees = [data]
        else:
            print("‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç JSON")
            return None
        
        print(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(employees)} —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤...")
        
        for i, employee_data in enumerate(employees):
            print(f"\nüë§ –°–æ—Ç—Ä—É–¥–Ω–∏–∫ {i+1}:")
            employee_id = employee_data.get('–§–ò–û', f'–°–æ—Ç—Ä—É–¥–Ω–∏–∫_{i+1}')
            print(f"   ID: {employee_id}")
            
            processed_data = self.process_single_employee(employee_data)
            
            if processed_data.empty:
                print(f"   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞")
                continue
            
            prediction_result = self.predict_burnout(processed_data)
            if prediction_result is None:
                continue
            
            interpretation = self.interpret_prediction(prediction_result)
            
            result = {
                'employee_id': employee_id,
                'prediction': prediction_result['prediction'],
                'burnout_probability': round(prediction_result['burnout_probability'], 4),
                'no_burnout_probability': round(prediction_result['no_burnout_probability'], 4),
                'confidence': round(prediction_result['confidence'], 4),
                'status': interpretation['status'],
                'recommendation': interpretation['recommendation'],
                'color': interpretation['color']
            }
            
            results.append(result)
            
            print(f"   {interpretation['color']} –°—Ç–∞—Ç—É—Å: {interpretation['status']}")
            print(f"   üìä –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã–≥–æ—Ä–∞–Ω–∏—è: {prediction_result['burnout_probability']:.1%}")
            print(f"   üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {interpretation['recommendation']}")
        
        return results

    def save_results(self, results, output_path='prediction_results.json'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON —Ñ–∞–π–ª"""
        try:
            serializable_results = []
            for result in results:
                serializable_result = {}
                for key, value in result.items():
                    if isinstance(value, (np.integer, np.int64)):
                        serializable_result[key] = int(value)
                    elif isinstance(value, (np.floating, np.float64)):
                        serializable_result[key] = float(value)
                    else:
                        serializable_result[key] = value
                serializable_results.append(serializable_result)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(serializable_results, f, ensure_ascii=False, indent=2)
            print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ JSON —Ñ–∞–π–ª–æ–≤"""
    import argparse
    
    parser = argparse.ArgumentParser(description='–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–≥–æ—Ä–∞–Ω–∏—è –∏–∑ JSON —Ñ–∞–π–ª–æ–≤')
    parser.add_argument('json_file', help='–ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤')
    parser.add_argument('--output', '-o', default='prediction_results.json', help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    parser.add_argument('--model', '-m', default='svm_model.pkl', help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏')
    
    args = parser.parse_args()
    
    print("üéØ –ó–ê–ü–£–°–ö –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø –í–´–ì–û–†–ê–ù–ò–Ø –ò–ó JSON")
    print("=" * 50)
    
    predictor = JSONPredictor(args.model)
    
    if predictor.model is None:
        return
    
    results = predictor.process_json_file(args.json_file)
    
    if results:
        predictor.save_results(results, args.output)
        
        burnout_count = sum(1 for r in results if r['prediction'] == 1)
        total_count = len(results)
        
        print(f"\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"   –í—Å–µ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {total_count}")
        print(f"   –° –≤—ã–≥–æ—Ä–∞–Ω–∏–µ–º: {burnout_count}")
        print(f"   –ë–µ–∑ –≤—ã–≥–æ—Ä–∞–Ω–∏—è: {total_count - burnout_count}")
        print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç –≤—ã–≥–æ—Ä–∞–Ω–∏—è: {burnout_count/total_count*100:.1f}%")

if __name__ == "__main__":
    main()